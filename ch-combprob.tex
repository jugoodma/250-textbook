\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Combinatorics and Probability}

\epigraph{What?!}{Lil Jon}

\minitoc

\section{Introduction}

This is \textit{Discrete} Mathematics, so we will be focusing on \textit{discrete} probability.

Let's put some more text here for now

\section{Combinatorics}

Imagine you are a software developer for a large company, \textit{Macrosoft}. Your manager assigned you to a project that needs testing. Your test cases must cover all execution paths. At first this seems like a daunting task, however you took discrete mathematics and learned about combinatorics. You can calculate exactly how many test cases you need. And so you do -- only to find out that you need \(9! = 362880\) test cases. In the fine words of JonTron, ``that's a lot of damage.''

\begin{defn}[Combinatorics\index{Combinatorics}]
	The area of mathematics dealing with counting
\end{defn}

\exsol{
	Count the number of elements in the following set: \[\{\emptyset, \{a\}, \{b\}, \{a,b\}\}\]
}{
	There are two ways to solve this problem. First, you can visually count the number of elements -- 1, 2, 3, 4. Otherwise, you can notice that the given set is the powerset of \(\{a,b\}\), which is a set of size 2. We know that \(|\mathcal{P}(A)| = 2^{|A|}\), so the number of elements is \(2^2 = 4\).
}

\begin{rem}
	There are almost always multiple valid ways to solve combinatorics problems. Some ways are better than others, though, because they can abstract out to larger inputs.
\end{rem}

\exsol{
	How many different orderings of the letters \textit{abc} can we create?
}{
	We can list all the possible orderings and count them: \textit{abc}, \textit{acb}, \textit{bac}, \textit{bca}, \textit{cab}, \textit{cba}.
	
	Alternatively, we can view this as a 3-letter word where we need to place letters in each of the three positions.
	
	\begin{center}
		\vspace{5mm}
		\rule{1cm}{1pt} \hspace{3mm} \rule{1cm}{1pt} \hspace{3mm} \rule{1cm}{1pt}
		\vspace{5mm}
	\end{center}
	
	For the first position, we have three possibilities: \textit{a}, \textit{b}, or \textit{c}. Then, we place that letter and move on to the second position where we can place one of the two remaining letters. In the last position, we place the remaining letter.
	
	So, \textit{for each} possibility in the first position, we have all possibilities for the second and third positions. So there are \(3 \times \) \textit{second/third position possibilities} total orderings. Then, journey into the second and third positions. There are two remaining letters, so there are \(2 \times \) \textit{third position possibilities} sub-orderings. There is one option in the last position, so putting this all together we get \(3 \times 2 \times 1 = 3! = 6\) total orderings.
}

%In the example above, we listed out all of the \textit{permutations} of the letters \textit{abc}.

\begin{defn}[Multiplication Rule\index{Combinatorics!Multiplication Rule}]
	Given some procedure \(E\) that can be broken down into a sequence of two tasks, if there are \(n_1\) ways to do the first task and for each of those ways there are \(n_2\) ways to do the second task, then the total number of ways to do procedure \(E\) is \(n_1 \times n_2\)
\end{defn}

we applied the mult rule to the previous example?

\begin{defn}[Permutations\index{Combinatorics!Permutations}]
	\textbf{Ordered} arrangements of \textit{all} elements in a set of size \(n\). By the multiplication rule, the total amount of permutations equals \[n!\]
\end{defn}

\begin{defn}[\(r\)-Permutation\index{Combinatorics!r-Permutations}]
	\textbf{Ordered} arrangements of \(r\) elements in a set of size \(n\). The total amount of \(r\)-permutations is denoted and equals \[P(n,r) = \frac{n!}{(n-r)!}\]
\end{defn}

\exsol{
	We are a combinatorics photographer. A group of 7 students walked into our office asking for all different possible pictures of them with only 3 people. Since we charge per-photo, how many such photos will we take?
}{
	We \textit{could} count out all of the options, but that might be too much work. Instead, we can translate the problem into a string problem like before. We want all possibilities of 3 people in a row:
	
	\begin{center}
		\vspace{5mm}
		\rule{1cm}{1pt} \hspace{3mm} \rule{1cm}{1pt} \hspace{3mm} \rule{1cm}{1pt}
		\vspace{5mm}
	\end{center}
	
	In the first position, we have 7 possibilities. Then, in the second position, we have 6 possibilities. Finally, in the third position, we have 5 possibilities. Thus, in total, we can make \(7 \times 6 \times 5\) photos.
	
	Alternatively, we could have used \(r\)-permutations. In this case, \(r = 3\) and \(n = 7\). So we are finding all 3-permutations of a set of size 7. This is \[P(7,3) = \frac{7!}{(7-3)!} = \frac{7!}{4!} = 7 \times 6 \times 5\]
}

\begin{defn}[\(r\)-Combinations\index{Combinatorics!Combinations}]
	(or just \textit{Combinations}) \textbf{Unordered} arrangements of \(r\) elements in a set of size \(n\). Alternatively, it is the number of \(r\)-sized subsets of a \(n\)-sized set. The total amount of combinations is denoted and equals \[C(n,r) = \binom{n}{r} = \frac{n!}{r!(n-r)!}\]
\end{defn}

\exsol{
	How many student committees of size 3 can we make from a student population of 7?
}{
	There is no notion of \textit{order} within a committee, so we want the number of 3-combinations from a set of size 7. So the answer is \[\binom{7}{3} = \frac{7!}{3!4!}\]
	
	Alternatively, we could first solve the problem as-if we care about the committee ordering, and then \textit{divide out} all of the different possible orderings per committee. For example, the ordered committees \(a,b,c\) and \(b,c,a\) should be counted as the same. So, how many orderings \textit{per-committee} can we make? \(3!\). Then, the total amount of ordered committees is \(P(7,3) = \frac{7!}{4!}\). So if we divide out \(3!\) we get \[\frac{P(7,3)}{3!} = \frac{7!}{3!4!} = \binom{7}{3}\]
}

\begin{rem}
	The previous example shows the relationship between permutations and combinations. % todo
\end{rem}

% todo
A mini-discussion on the differences between ordering and replacement.

\begin{figure}[H]
	\centering
	\begin{tabular}{ccc}
		& With Replacement & Without Replacement \\
		\midrule
		Order Matters & \(n^k\) & \(P(n,k) = \frac{n!}{(n-k)!}\) \\
		\midrule
		Order Does Not Matter & \(\binom{n+k-1}{n-1}\) & \(\binom{n}{k} = \frac{n!}{k!(n-k)!}\) \\
	\end{tabular}
	\caption{Ordering and Replacement -- picking \(k\) elements from \(n\) total elements}
\end{figure}

\begin{rem}
	For explanation on unordered sampling with replacement, \href{https://www.probabilitycourse.com/chapter2/2_1_4_unordered_with_replacement.php}{see here}.
\end{rem}

\section{The Inclusion-Exclusion Principle}

\begin{thm}[The Inclusion-Exclusion Principle]
	
\end{thm}



\section{Pigeonhole Principle}

\begin{thm}[The Pigeonhole Principle]
	
\end{thm}

\begin{thm}[Generalized Pigeonhole Principle]
	
\end{thm}

\section{Discrete Probability}

Intro text here

\begin{defn}[Probability\index{Probability}]
	The likelihood (percent chance) that an event occurs. Probabilities of every possible event should add to 1
\end{defn}

\begin{example}
	
\end{example}

Something else here

\begin{example}
	Harder example
\end{example}

Joint/Disjoint

\begin{defn}[Joint Probability\index{Probability!Joint}]
	
\end{defn}

\begin{defn}[Independence\index{Probability!Independence}]
	
\end{defn}

Some discussion on conditional probability

\begin{defn}[Conditional Probability\index{Probability!Conditional}]
	
\end{defn}

\begin{defn}[Conditional Probability\index{Probability!Conditional}]
	
\end{defn}

Probably talk about 

\section{Basic Statistics\index{Statistics}}

Statistics are an important application of probability. Statistics give us a way to mathematically model probabilities of big events/experiments. We cover three fundamental statistics principles, along with a few related topics.

\begin{defn}[Expected Value\index{Statistics!Expected Value}]
	\(\mathbb{E}[X] = \mu_X = \sum_{x}^{} x \cdot \mathrm{Pr}(X = x)\). This is a generalization of the \textit{arithmetic mean}, which is defined in scenarios where outcomes are equally likely. If we denote \(x_1,\ x_2,\ x_3,\ \cdots,\ x_n\) to be the values outputted by \(X\), and \(p_1,\ p_2,\ p_3,\ \cdots,\ p_n\) to be their respective probabilities, then \(\mathbb{E}[X] = \sum_{i=1}^{n} x_i p_i\)
\end{defn}

Sometimes students confuse \textit{expected value} with \textit{average}. First, the ``average'' is not well-defined -- it could refer to the mean, median, or mode (typically it refers to the mean). Second, as stated in the definition, the expected value is a generalized \textit{mean}.

\begin{defn}[Variance\index{Statistics!Variance}]
	
\end{defn}

\begin{defn}[Standard Deviation\index{Statistics!Standard Deviation}]
	
\end{defn}

\section{Summary}

\begin{itemize}
	\item 1
	\item 2
	\item 3
\end{itemize}

\section{Practice}

\begin{enumerate}
	\item q
	\item 2 of 20 light-bulbs are defective. You select 2 light-bulbs at random. What is the probability that neither bulb selected is defective?
	% (18/20) * (17/19)
	\item q
\end{enumerate}
\end{document}